{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhealth\n",
    "import pandas as pd\n",
    "from typing import *\n",
    "import numpy as np\n",
    "from pyhealth.models import Transformer, RNN\n",
    "from itertools import chain\n",
    "import random\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiolung_df = pd.read_excel(\"20230713_BDMetaData_CanRuti.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_dict(batch):\n",
    "    return {key: [d[key] for d in batch] for key in batch[0]}\n",
    "\n",
    "\n",
    "\n",
    "class RadioLungDataset():\n",
    "    \n",
    "    def __init__(self, path_df: str):\n",
    "        \n",
    "        self.df = pd.read_excel(path_df)\n",
    "        self.input_info = {} # com estan cada feature_key\n",
    "        self.map_feature_token_space()\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def map_feature_token_space(self) -> None:\n",
    "        feature_keys = self.df.columns\n",
    "        for feature_key in feature_keys:\n",
    "           \n",
    "            token_space = self.df[feature_key].unique().tolist() #token_space = self.df[feature_key].unique().flatten().tolist()\n",
    "            if pd.api.types.is_string_dtype(self.df[feature_key] ) == True:\n",
    "                self.input_info[feature_key] = {\"type\": str, \"dim\": 2} \n",
    "            else:\n",
    "                self.input_info[feature_key] = {\"type\": int, \"dim\": 2, 'len':1}# ha petat i tb i he ficat len \n",
    "             \n",
    "                self.df[feature_key]= (self.df[feature_key].apply(lambda x: [x])) # he ficat tots es num dins una llista pq vol aquest format\n",
    "            \n",
    "           #todo: modificar pq puguis ficar aquesta linia enlloc de int/float -->  (type(self.df[feature_key].iloc[0]).__name__)\n",
    "\n",
    "\n",
    "    def case1_case2_binary(self): #s'han de natejar dades crec\n",
    "        feature_bin = [\"air_pollution\", \"ph_cancer\", \"COPD\", \"ASTHMA\", \"bronchiectasis\", \"TB\", \"pneumonia\"]\n",
    "        \n",
    "        dic_bi = {}\n",
    "        for i, feature in enumerate(feature_bin):\n",
    "            dic_bi[feature] = {0: i * 2, 1: i * 2 + 1}\n",
    "        \n",
    "        for feature in feature_bin:\n",
    "            self.df[feature] = self.df[feature].map(dic_bi[feature])\n",
    "        print(self.df['TB'])\n",
    "        return dic_bi\n",
    "      \n",
    "         \n",
    "    def get_all_tokens(self, key:str):\n",
    "        return self.df[key].unique().flatten().tolist()\n",
    "    \n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.df.iloc[idx]\n",
    "        sample_return = {fkey: [value] if fkey != \"type\" else value for fkey, value in sample.items()}\n",
    "        sample_return.update({\"patient_id\": sample_return[\"id\"]})\n",
    "        sample_return.pop(\"id\")\n",
    "        return sample_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RadioLungDataset(path_df=\"20230713_BDMetaData_CanRuti.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Malignant', 'Benign', nan]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[3]\n",
    "dataset.input_info\n",
    "dataset.get_all_tokens(key=\"type\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(dataset=dataset, \n",
    "                    feature_keys=[\"sex\", \"BMI\",'lobe','global_location','histological_diagnosis'],\n",
    "                    label_key=\"type\", # imagin que es lo que s'ha de predir\n",
    "                    mode=\"multiclass\", # no hi ha nateja de dataset i posa que hi ha 3 tipus enlloc de ser binari\n",
    "                    embedding_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_patient(\n",
    "    dataset,\n",
    "    ratios: Union[Tuple[float, float, float], List[float]],\n",
    "    seed: Optional[int] = None,):\n",
    "\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    assert sum(ratios) == 1.0, \"ratios must sum to 1.0\"\n",
    "    patient_ids = [dataset[i]['patient_id'][0] for i in range(len(dataset))]\n",
    "    num_patients = len(patient_ids)\n",
    "    \n",
    "    idx = np.arange(num_patients)  \n",
    "\n",
    "    train_index, temp_idx = train_test_split(idx, test_size=0.3, random_state=42)\n",
    "    val_index, test_index = train_test_split(temp_idx, test_size=0.5, random_state=42)  \n",
    "\n",
    "    train_dataset = torch.utils.data.Subset(dataset, train_index)\n",
    "    val_dataset = torch.utils.data.Subset(dataset, val_index)\n",
    "    test_dataset = torch.utils.data.Subset(dataset, test_index)\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = split_by_patient(dataset, (0.8, 0.1, 0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_dataloader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = get_dataloader(val_ds, batch_size=32, shuffle=False)\n",
    "test_loader = get_dataloader(test_ds, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['hospital', 'birthdate', 'sex', 'education', 'BMI', 'smoking', 'packyear_index', 'air_pollution', 'fh_cancer', 'ph_cancer', 'COPD', 'ASTHMA', 'bronchiectasis', 'TB', 'pneumonia', 'FVC', 'FVCL', 'FEV1', 'FEV1L', 'indice', 'DLCO', 'id.1', 'patient_id', 'nodule_id', 'ct_id', 'ct_id_DB', 'petscan_id', 'surgery_id', 'date', 'type', 'lobe', 'global_location', 'xray', 'tsize', 'cdiff', 'necrosis', 'vinfiltration', 'histological_diagnosis', 'TNM', 'CD34', 'CD8', 'PDL1', 'WasItDone', 'IfDone', 'whichtest', 'whichtest2', 'id.2', 'hospital.1', 'date.1', 'hospital_ct', 'slice_thickness', 'nodule_diameter', 'nodule_shape', 'nodule_density', 'emphysema', 'contrast', 'lowdosect', 'CTFile'])\n",
      "['Malignant', 'Malignant', 'Malignant', 'Benign', 'Malignant', 'Benign', 'Malignant', 'Malignant', 'Malignant', 'Benign', 'Malignant', 'Benign', nan, 'Malignant', 'Benign', 'Benign', 'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Benign', 'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Malignant', 'Benign']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_batch = next(iter(train_loader))\n",
    "print(data_batch.keys())\n",
    "print(data_batch[\"type\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(dataset=dataset, \n",
    "                    feature_keys=[\"sex\", \"BMI\",'lobe','global_location','histological_diagnosis'],\n",
    "                    label_key=\"type\", # imagin que es lo que s'ha de predir\n",
    "                    mode=\"multiclass\", # no hi ha nateja de dataset i posa que hi ha 3 tipus enlloc de ser binari\n",
    "                    embedding_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, object in enumerate(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (embeddings): ModuleDict(\n",
      "    (sex): Embedding(4, 128, padding_idx=0)\n",
      "    (lobe): Embedding(7, 128, padding_idx=0)\n",
      "    (global_location): Embedding(6, 128, padding_idx=0)\n",
      "    (histological_diagnosis): Embedding(13, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict(\n",
      "    (BMI): Linear(in_features=1, out_features=128, bias=True)\n",
      "  )\n",
      "  (transformer): ModuleDict(\n",
      "    (sex): TransformerLayer(\n",
      "      (transformer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadedAttention(\n",
      "            (linear_layers): ModuleList(\n",
      "              (0-2): 3 x Linear(in_features=128, out_features=128, bias=False)\n",
      "            )\n",
      "            (output_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (attention): Attention()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (feed_forward): PositionwiseFeedForward(\n",
      "            (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (activation): GELU(approximate='none')\n",
      "          )\n",
      "          (input_sublayer): SublayerConnection(\n",
      "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (output_sublayer): SublayerConnection(\n",
      "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (BMI): TransformerLayer(\n",
      "      (transformer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadedAttention(\n",
      "            (linear_layers): ModuleList(\n",
      "              (0-2): 3 x Linear(in_features=128, out_features=128, bias=False)\n",
      "            )\n",
      "            (output_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (attention): Attention()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (feed_forward): PositionwiseFeedForward(\n",
      "            (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (activation): GELU(approximate='none')\n",
      "          )\n",
      "          (input_sublayer): SublayerConnection(\n",
      "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (output_sublayer): SublayerConnection(\n",
      "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (lobe): TransformerLayer(\n",
      "      (transformer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadedAttention(\n",
      "            (linear_layers): ModuleList(\n",
      "              (0-2): 3 x Linear(in_features=128, out_features=128, bias=False)\n",
      "            )\n",
      "            (output_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (attention): Attention()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (feed_forward): PositionwiseFeedForward(\n",
      "            (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (activation): GELU(approximate='none')\n",
      "          )\n",
      "          (input_sublayer): SublayerConnection(\n",
      "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (output_sublayer): SublayerConnection(\n",
      "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (global_location): TransformerLayer(\n",
      "      (transformer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadedAttention(\n",
      "            (linear_layers): ModuleList(\n",
      "              (0-2): 3 x Linear(in_features=128, out_features=128, bias=False)\n",
      "            )\n",
      "            (output_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (attention): Attention()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (feed_forward): PositionwiseFeedForward(\n",
      "            (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (activation): GELU(approximate='none')\n",
      "          )\n",
      "          (input_sublayer): SublayerConnection(\n",
      "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (output_sublayer): SublayerConnection(\n",
      "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (histological_diagnosis): TransformerLayer(\n",
      "      (transformer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadedAttention(\n",
      "            (linear_layers): ModuleList(\n",
      "              (0-2): 3 x Linear(in_features=128, out_features=128, bias=False)\n",
      "            )\n",
      "            (output_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (attention): Attention()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (feed_forward): PositionwiseFeedForward(\n",
      "            (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (activation): GELU(approximate='none')\n",
      "          )\n",
      "          (input_sublayer): SublayerConnection(\n",
      "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (output_sublayer): SublayerConnection(\n",
      "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=640, out_features=3, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.adam.Adam'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000016B03F8F4F0>\n",
      "Monitor: None\n",
      "Monitor criterion: max\n",
      "Epochs: 50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 50: 100%|██████████| 3/3 [00:02<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holhaestic mirant es batch \n",
      " [[0.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[0.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[28.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-0, step-3 ---\n",
      "loss: 1.2279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 70.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-0, step-3 ---\n",
      "accuracy: 0.9333\n",
      "f1_macro: 0.9068\n",
      "f1_micro: 0.9333\n",
      "loss: 0.3691\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[28.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[33.5]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[28.8]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 50: 100%|██████████| 3/3 [00:00<00:00, 35.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-6 ---\n",
      "loss: 0.5780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 77.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-1, step-6 ---\n",
      "accuracy: 0.9333\n",
      "f1_macro: 0.9068\n",
      "f1_micro: 0.9333\n",
      "loss: 0.0964\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[25.1]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[26.3]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[23.8]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 / 50: 100%|██████████| 3/3 [00:00<00:00, 31.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-2, step-9 ---\n",
      "loss: 0.7505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 52.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-2, step-9 ---\n",
      "accuracy: 0.9333\n",
      "f1_macro: 0.9068\n",
      "f1_micro: 0.9333\n",
      "loss: 0.3067\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[28.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 / 50: 100%|██████████| 3/3 [00:00<00:00, 31.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[0.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.8]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-3, step-12 ---\n",
      "loss: 0.3084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 57.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-3, step-12 ---\n",
      "accuracy: 0.9333\n",
      "f1_macro: 0.9068\n",
      "f1_micro: 0.9333\n",
      "loss: 0.4098\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[20.8]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[33.5]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 50: 100%|██████████| 3/3 [00:00<00:00, 21.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-4, step-15 ---\n",
      "loss: 0.2161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 57.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-4, step-15 ---\n",
      "accuracy: 0.9333\n",
      "f1_macro: 0.9068\n",
      "f1_micro: 0.9333\n",
      "loss: 0.2868\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[31.9]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[33.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[0.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 / 50: 100%|██████████| 3/3 [00:00<00:00, 30.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-5, step-18 ---\n",
      "loss: 0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 82.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-5, step-18 ---\n",
      "accuracy: 0.9333\n",
      "f1_macro: 0.9068\n",
      "f1_micro: 0.9333\n",
      "loss: 0.1226\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[26.6]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[31.9]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[31.9]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 / 50: 100%|██████████| 3/3 [00:00<00:00, 32.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-6, step-21 ---\n",
      "loss: 0.0113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 62.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-6, step-21 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0279\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[22.8]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[33.8]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[33.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 50: 100%|██████████| 3/3 [00:00<00:00, 31.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-7, step-24 ---\n",
      "loss: 0.0540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 56.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-7, step-24 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0028\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[19.4]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[26.7]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.8]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 / 50: 100%|██████████| 3/3 [00:00<00:00, 24.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 / 50: 100%|██████████| 3/3 [00:00<00:00, 24.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-27 ---\n",
      "loss: 0.0533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 67.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-8, step-27 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0004\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[0.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 / 50: 100%|██████████| 3/3 [00:00<00:00, 32.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holhaestic mirant es batch \n",
      " [[23.4]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[19.8]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-9, step-30 ---\n",
      "loss: 0.0481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 75.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-9, step-30 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0002\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[28.3]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[24.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[23.4]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 / 50: 100%|██████████| 3/3 [00:00<00:00, 27.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-10, step-33 ---\n",
      "loss: 0.0795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 60.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-10, step-33 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[28.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[26.2]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 / 50: 100%|██████████| 3/3 [00:00<00:00, 33.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[24.6]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-11, step-36 ---\n",
      "loss: 0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 69.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-11, step-36 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro: 1.0000\n",
      "loss: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.4]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 / 50:  67%|██████▋   | 2/3 [00:00<00:00, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holhaestic mirant es batch \n",
      " [[28.6]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 / 50: 100%|██████████| 3/3 [00:00<00:00, 22.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[28.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-12, step-39 ---\n",
      "loss: 0.0572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 68.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-12, step-39 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0002\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 / 50: 100%|██████████| 3/3 [00:00<00:00, 34.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[30.2]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[23.4]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[33.5]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-13, step-42 ---\n",
      "loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 65.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-13, step-42 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0005\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[29.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[28.3]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[31.9]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 / 50: 100%|██████████| 3/3 [00:00<00:00, 32.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-14, step-45 ---\n",
      "loss: 0.0504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 75.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-14, step-45 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0003\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[28.3]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[22.9]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 / 50: 100%|██████████| 3/3 [00:00<00:00, 35.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[24.1]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-15, step-48 ---\n",
      "loss: 0.0233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 63.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-15, step-48 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0002\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[0.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.4]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 / 50: 100%|██████████| 3/3 [00:00<00:00, 24.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holhaestic mirant es batch \n",
      " [[28.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 / 50: 100%|██████████| 3/3 [00:00<00:00, 24.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-16, step-51 ---\n",
      "loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 47.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-16, step-51 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0002\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[0.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[21.8]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[24.0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 / 50: 100%|██████████| 3/3 [00:00<00:00, 28.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-17, step-54 ---\n",
      "loss: 0.0497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 63.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-17, step-54 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0002\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[29.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 / 50: 100%|██████████| 3/3 [00:00<00:00, 29.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[0.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[33.3]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 / 50: 100%|██████████| 3/3 [00:00<00:00, 29.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-18, step-57 ---\n",
      "loss: 0.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 49.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-18, step-57 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[34.7]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[25.9]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[22.8]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 / 50: 100%|██████████| 3/3 [00:00<00:00, 32.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-19, step-60 ---\n",
      "loss: 0.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 60.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-19, step-60 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[26.3]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[33.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[24.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 / 50: 100%|██████████| 3/3 [00:00<00:00, 21.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 / 50: 100%|██████████| 3/3 [00:00<00:00, 21.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-20, step-63 ---\n",
      "loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 74.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-20, step-63 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[28.9]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[34.7]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[26.6]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 / 50: 100%|██████████| 3/3 [00:00<00:00, 31.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-21, step-66 ---\n",
      "loss: 0.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 77.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-21, step-66 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[21.2]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 / 50: 100%|██████████| 3/3 [00:00<00:00, 31.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[24.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[28.7]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-22, step-69 ---\n",
      "loss: 0.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 61.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-22, step-69 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[28.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 / 50: 100%|██████████| 3/3 [00:00<00:00, 30.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holhaestic mirant es batch \n",
      " [[29.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[28.3]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-23, step-72 ---\n",
      "loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 65.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-23, step-72 ---\n",
      "accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[22.3]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 / 50:  67%|██████▋   | 2/3 [00:00<00:00, 17.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[29.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 / 50: 100%|██████████| 3/3 [00:00<00:00, 20.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[26.2]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-24, step-75 ---\n",
      "loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 70.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-24, step-75 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[21.8]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[25.9]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[26.2]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 / 50: 100%|██████████| 3/3 [00:00<00:00, 30.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-25, step-78 ---\n",
      "loss: 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 70.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-25, step-78 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[22.8]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.5]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 / 50: 100%|██████████| 3/3 [00:00<00:00, 30.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[26.3]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-26, step-81 ---\n",
      "loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 75.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-26, step-81 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[26.6]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 / 50: 100%|██████████| 3/3 [00:00<00:00, 29.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holhaestic mirant es batch \n",
      " [[28.3]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[24.6]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 / 50: 100%|██████████| 3/3 [00:00<00:00, 29.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-27, step-84 ---\n",
      "loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 62.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-27, step-84 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[33.8]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 / 50: 100%|██████████| 3/3 [00:00<00:00, 26.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[24.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[19.8]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 / 50: 100%|██████████| 3/3 [00:00<00:00, 26.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-28, step-87 ---\n",
      "loss: 0.0191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 68.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-28, step-87 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[24.1]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[25.7]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 / 50: 100%|██████████| 3/3 [00:00<00:00, 32.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[28.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-29, step-90 ---\n",
      "loss: 0.1119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 69.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-29, step-90 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 / 50: 100%|██████████| 3/3 [00:00<00:00,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.8]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.5]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[25.6]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-30, step-93 ---\n",
      "loss: 0.0013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 57.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-30, step-93 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[25.7]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[28.7]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31 / 50: 100%|██████████| 3/3 [00:00<00:00, 29.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-31, step-96 ---\n",
      "loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 59.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-31, step-96 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.4]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[24.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32 / 50: 100%|██████████| 3/3 [00:00<00:00, 33.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[23.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-32, step-99 ---\n",
      "loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 59.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Eval epoch-32, step-99 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[33.8]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.8]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33 / 50: 100%|██████████| 3/3 [00:00<00:00, 34.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[28.3]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-33, step-102 ---\n",
      "loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 74.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-33, step-102 ---\n",
      "accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[30.2]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[24.1]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34 / 50: 100%|██████████| 3/3 [00:00<00:00, 39.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[29.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-34, step-105 ---\n",
      "loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 90.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-34, step-105 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[29.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35 / 50: 100%|██████████| 3/3 [00:00<00:00, 33.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holhaestic mirant es batch \n",
      " [[21.2]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-35, step-108 ---\n",
      "loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 90.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-35, step-108 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[0.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[22.8]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36 / 50: 100%|██████████| 3/3 [00:00<00:00, 40.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holhaestic mirant es batch \n",
      " [[33.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-36, step-111 ---\n",
      "loss: 0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 64.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-36, step-111 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[25.7]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[0.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37 / 50: 100%|██████████| 3/3 [00:00<00:00, 38.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[22.3]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-37, step-114 ---\n",
      "loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 89.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-37, step-114 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[23.3]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[26.3]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38 / 50: 100%|██████████| 3/3 [00:00<00:00, 36.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holhaestic mirant es batch \n",
      " [[28.7]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-38, step-117 ---\n",
      "loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 82.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-38, step-117 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[28.8]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[33.8]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[28.3]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39 / 50: 100%|██████████| 3/3 [00:00<00:00, 39.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-39, step-120 ---\n",
      "loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 87.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-39, step-120 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[19.8]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[26.2]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40 / 50: 100%|██████████| 3/3 [00:00<00:00, 39.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holhaestic mirant es batch \n",
      " [[27.5]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-40, step-123 ---\n",
      "loss: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 85.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-40, step-123 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 41 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[31.9]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[30.3]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[23.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41 / 50: 100%|██████████| 3/3 [00:00<00:00, 28.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-41, step-126 ---\n",
      "loss: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 68.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-41, step-126 ---\n",
      "accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[33.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.8]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42 / 50: 100%|██████████| 3/3 [00:00<00:00, 35.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[33.3]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-42, step-129 ---\n",
      "loss: 0.0080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 78.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-42, step-129 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[30.3]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[33.8]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43 / 50: 100%|██████████| 3/3 [00:00<00:00, 37.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holhaestic mirant es batch \n",
      " [[29.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-43, step-132 ---\n",
      "loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 70.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-43, step-132 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 44 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[25.9]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.8]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44 / 50: 100%|██████████| 3/3 [00:00<00:00, 33.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holhaestic mirant es batch \n",
      " [[32.2]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-44, step-135 ---\n",
      "loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 63.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-44, step-135 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 45 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[28.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[28.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[33.3]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45 / 50: 100%|██████████| 3/3 [00:00<00:00, 34.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-45, step-138 ---\n",
      "loss: 0.0051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 86.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-45, step-138 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 46 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[20.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[0.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46 / 50: 100%|██████████| 3/3 [00:00<00:00, 34.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holhaestic mirant es batch \n",
      " [[28.3]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-46, step-141 ---\n",
      "loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 68.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-46, step-141 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 47 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.5]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[22.3]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47 / 50: 100%|██████████| 3/3 [00:00<00:00, 37.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holhaestic mirant es batch \n",
      " [[25.7]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-47, step-144 ---\n",
      "loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 82.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-47, step-144 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 48 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[20.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[26.2]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[25.7]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48 / 50: 100%|██████████| 3/3 [00:00<00:00, 37.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train epoch-48, step-147 ---\n",
      "loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 86.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-48, step-147 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 49 / 50:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[20.8]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.5]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[33.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49 / 50: 100%|██████████| 3/3 [00:00<00:00, 35.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Train epoch-49, step-150 ---\n",
      "loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation: 100%|██████████| 1/1 [00:00<00:00, 61.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n",
      "holhaestic mirant es batch \n",
      " [[27.0]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n",
      "--- Eval epoch-49, step-150 ---\n",
      "accuracy: 1.0000\n",
      "f1_macro: 1.0000\n",
      "f1_micro: 1.0000\n",
      "loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pyhealth.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(model=model)\n",
    "trainer.train(\n",
    "train_dataloader=train_loader,\n",
    "val_dataloader=val_loader,\n",
    "epochs=50,\n",
    "\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'sex'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m # for case 3: [[1.5, 2.0, 0.0], ...]\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m            elif (dim_ == 2) and (type_ in [float, int]):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m                mask = mask.bool().to(self.device)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# try the model\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m ret \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata_batch)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(ret)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# try loss backward\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xisca\\anaconda\\envs\\deep\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\xisca\\anaconda\\envs\\deep\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xisca\\anaconda\\envs\\deep\\lib\\site-packages\\pyhealth\\models\\transformer.py:391\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;66;03m# for case 1: [code1, code2, code3, ...]\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (dim_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (type_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    389\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeat_tokenizers[feature_key]\u001b[38;5;241m.\u001b[39mbatch_encode_2d(\n\u001b[0;32m    390\u001b[0m         kwargs[feature_key]\n\u001b[1;32m--> 391\u001b[0m     )\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;66;03m# (patient, event)\u001b[39;00m\n\u001b[0;32m    393\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(x, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sex'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    " # for case 3: [[1.5, 2.0, 0.0], ...]\n",
    "            elif (dim_ == 2) and (type_ in [float, int]):\n",
    "                import pdb\n",
    "                pdb.set_trace()\n",
    "                x, mask = self.padding2d(kwargs[feature_key])\n",
    "                # (patient, event, values)\n",
    "                x = torch.tensor(x, dtype=torch.float, device=self.device)\n",
    "                # (patient, event, embedding_dim)\n",
    "                x = self.linear_layers[feature_key](x)\n",
    "                # (patient, event)\n",
    "                mask = mask.bool().to(self.device)\n",
    "\"\"\"\n",
    "\n",
    "# try the model\n",
    "ret = model(**data_batch)\n",
    "print(ret)\n",
    "\n",
    "# try loss backward\n",
    "ret[\"loss\"].backward()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6ACB0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 1/1 [00:02<00:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holhaestic mirant es batch \n",
      " [[24.4]]\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B046F1090>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BB20>\n",
      "\n",
      "\n",
      "712873817238\n",
      "\n",
      " <pyhealth.tokenizer.Tokenizer object at 0x0000016B07C6BD30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 1.0,\n",
       " 'f1_macro': 1.0,\n",
       " 'f1_micro': 1.0,\n",
       " 'loss': 0.00036061316495761275}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COSES QUE HE FET PERO QUE NO SERVEIXEN EN GENERAL PER RES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Woman' ' Man']\n",
      "[' No', ' No', ' No', ' No', ' No', ' No', ' No', ' (Yes) others', ' (Yes) others', ' No', ' No', ' No', ' No', ' No', ' No', ' No', ' (Yes) others', ' No', ' No', ' No', ' No', ' No', ' No', ' No', ' No', ' (Yes) others', ' No', ' No', ' No', ' No', '(Yes) Lung cancer', ' (Yes) others', ' No', '(Yes) Lung cancer', ' No', ' (Yes) others', '(Yes) Lung cancer', ' No', ' (Yes) others', ' No', ' (Yes) others', ' No', ' No', '(Yes) Lung cancer', ' (Yes) others', ' (Yes) others', ' No', ' No', ' No', ' (Yes) others', '(Yes) others', '(Yes) Lung cancer', nan, ' No', ' No', nan, '(Yes) others', '(Yes) Lung cancer', ' No', ' No', nan, ' No', ' No', '(Yes) others', '(Yes) Lung cancer', '(Yes) Lung cancer', ' No', ' No', '(Yes) others', ' No', ' No', '(Yes) others', nan, ' No', '(Yes) Lung cancer', '(Yes) others', ' No', ' No', nan, '(Yes) others', ' No', nan, nan, '(Yes) others', ' No', nan, '(Yes) others', nan, '(Yes) Lung cancer', ' No', ' No', ' No', '(Yes) others', ' No', '(Yes) others', '(Yes) others', nan, '(Yes) Lung cancer', '(Yes) Lung cancer']\n"
     ]
    }
   ],
   "source": [
    "from pyhealth.tokenizer import Tokenizer\n",
    "print(radiolung_df[\"sex\"].unique())\n",
    "token_space = radiolung_df[[\"fh_cancer\"]].to_numpy().flatten().tolist()\n",
    "print(token_space\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(tokens=token_space, special_tokens=[\"<pad>\", \"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " '<unk>': 1,\n",
       " ' No': 2,\n",
       " ' (Yes) others': 3,\n",
       " '(Yes) Lung cancer': 4,\n",
       " '(Yes) others': 5,\n",
       " nan: 6}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocabulary.token2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_indices([\"hola\", \"pepe\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123123\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Transformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m get_dataloader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# model\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTransformer\u001b[49m(\n\u001b[0;32m     47\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[0;32m     48\u001b[0m     feature_keys\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_codes\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_vectors\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_list_codes\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_list_vectors\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     53\u001b[0m     ],\n\u001b[0;32m     54\u001b[0m     label_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     55\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     56\u001b[0m )\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# data batch\u001b[39;00m\n\u001b[0;32m     59\u001b[0m data_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Transformer' is not defined"
     ]
    }
   ],
   "source": [
    "from pyhealth.datasets import SampleEHRDataset\n",
    "\n",
    "samples = [\n",
    "    {\n",
    "        \"patient_id\": \"patient-0\",\n",
    "        \"visit_id\": \"visit-0\",\n",
    "        \"single_vector\": [1, 2, 3],\n",
    "        \"list_codes\": [\"505800458\"],  # NDC\n",
    "        \"list_vectors\": [[1.0, 2.55, 3.4], [4.1, 5.5, 6.0]],\n",
    "        \"list_list_codes\": [[\"A05B\", \"A05C\", \"A06A\"], [\"A11D\", \"A11E\"]],  # ATC-4\n",
    "        \"list_list_vectors\": [\n",
    "            [[1.8, 2.25, 3.41], [4.50, 5.9, 6.0]],\n",
    "            [[7.7, 8.5, 9.4]],\n",
    "        ],\n",
    "        \"label\": 1,\n",
    "    },\n",
    "    {\n",
    "        \"patient_id\": \"patient-0\",\n",
    "        \"visit_id\": \"visit-1\",\n",
    "        \"single_vector\": [1, 5, 8],\n",
    "        \"list_codes\": [\n",
    "            \"55154191800\",\n",
    "            \"551541928\",\n",
    "            \"55154192800\",\n",
    "            \"705182798\",\n",
    "            \"70518279800\",\n",
    "        ],\n",
    "        \"list_vectors\": [[1.4, 3.2, 3.5], [4.1, 5.9, 1.7], [4.5, 5.9, 1.7]],\n",
    "        \"list_list_codes\": [[\"A04A\", \"B035\", \"C129\"]],\n",
    "        \"list_list_vectors\": [\n",
    "            [[1.0, 2.8, 3.3], [4.9, 5.0, 6.6], [7.7, 8.4, 1.3], [7.7, 8.4, 1.3]],\n",
    "        ],\n",
    "        \"label\": 0,\n",
    "    },\n",
    "]\n",
    "\n",
    "# dataset\n",
    "dataset = SampleEHRDataset(samples=samples, dataset_name=\"test\")\n",
    "\n",
    "# data loader\n",
    "from pyhealth.datasets import get_dataloader\n",
    "\n",
    "train_loader = get_dataloader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# model\n",
    "model = Transformer(\n",
    "    dataset=dataset,\n",
    "    feature_keys=[\n",
    "        \"list_codes\",\n",
    "        \"list_vectors\",\n",
    "        \"list_list_codes\",\n",
    "        \"list_list_vectors\",\n",
    "    ],\n",
    "    label_key=\"label\",\n",
    "    mode=\"multiclass\",\n",
    ")\n",
    "\n",
    "# data batch\n",
    "data_batch = next(iter(train_loader))\n",
    "\n",
    "print(data_batch)\n",
    "\n",
    "# try the model\n",
    "ret = model(**data_batch)\n",
    "print(ret)\n",
    "\n",
    "# try loss backward\n",
    "ret[\"loss\"].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Attention(nn.Module):\n",
    "    def forward(self, query, key, value, mask=None, dropout=None):\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(query.size(-1))\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        p_attn = torch.softmax(scores, dim=-1)\n",
    "        if mask is not None:\n",
    "            p_attn = p_attn.masked_fill(mask == 0, 0)\n",
    "        if dropout is not None:\n",
    "            p_attn = dropout(p_attn)\n",
    " \n",
    "        return torch.matmul(p_attn, value), p_attn\n",
    "\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "    \n",
    "        self.linear_layers = nn.ModuleList(\n",
    "            [nn.Linear(d_model, d_model, bias=False) for _ in range(3)]\n",
    "        )\n",
    "        self.output_linear = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.attention = Attention()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.attn_gradients = None\n",
    "        self.attn_map = None\n",
    "\n",
    "    # helper functions for interpretability\n",
    "    def get_attn_map(self):\n",
    "        return self.attn_map \n",
    "    \n",
    "    def get_attn_grad(self):\n",
    "        return self.attn_gradients\n",
    "\n",
    "    def save_attn_grad(self, attn_grad):\n",
    "        self.attn_gradients = attn_grad \n",
    "\n",
    "    # register_hook option allows us to save the gradients in backwarding\n",
    "    def forward(self, query, key, value, mask=None, register_hook = False):\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        query, key, value = [\n",
    "            l(x).view(batch_size, -1, self.h, self.d_k).transpose(1, 2)\n",
    "            for l, x in zip(self.linear_layers, (query, key, value))\n",
    "        ]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch.\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)\n",
    "        x, attn = self.attention(query, key, value, mask=mask, dropout=self.dropout)\n",
    "        \n",
    "        self.attn_map = attn # save the attention map\n",
    "        if register_hook:\n",
    "            attn.register_hook(self.save_attn_grad)\n",
    "        # 3) \"Concat\" using a view and apply a final linear.\n",
    "        x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.h * self.d_k)\n",
    "  \n",
    "        return self.output_linear(x)\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = nn.GELU()\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.w_2(self.dropout(self.activation(self.w_1(x))))\n",
    "        if mask is not None:\n",
    "            mask = mask.sum(dim=-1) > 0\n",
    "            x[~mask] = 0\n",
    "        return x\n",
    "\n",
    "\n",
    "class SublayerConnection(nn.Module):\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = nn.LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\"Transformer block.\n",
    "\n",
    "    MultiHeadedAttention + PositionwiseFeedForward + SublayerConnection\n",
    "\n",
    "    Args:\n",
    "        hidden: hidden size of transformer.\n",
    "        attn_heads: head sizes of multi-head attention.\n",
    "        dropout: dropout rate.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden, attn_heads, dropout):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = MultiHeadedAttention(h=attn_heads, d_model=hidden)\n",
    "        self.feed_forward = PositionwiseFeedForward(\n",
    "            d_model=hidden, d_ff=4 * hidden, dropout=dropout\n",
    "        )\n",
    "        self.input_sublayer = SublayerConnection(size=hidden, dropout=dropout)\n",
    "        self.output_sublayer = SublayerConnection(size=hidden, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, mask=None, register_hook = False):\n",
    "        \"\"\"Forward propagation.\n",
    "\n",
    "        Args:\n",
    "            x: [batch_size, seq_len, hidden]\n",
    "            mask: [batch_size, seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            A tensor of shape [batch_size, seq_len, hidden]\n",
    "        \"\"\"\n",
    "        x = self.input_sublayer(x, lambda _x: self.attention(_x, _x, _x, mask=mask, register_hook=register_hook))\n",
    "        x = self.output_sublayer(x, lambda _x: self.feed_forward(_x, mask=mask))\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerLayer(nn.Module):\n",
    "    \"\"\"Transformer layer.\n",
    "\n",
    "    Paper: Ashish Vaswani et al. Attention is all you need. NIPS 2017.\n",
    "\n",
    "    This layer is used in the Transformer model. But it can also be used\n",
    "    as a standalone layer.\n",
    "\n",
    "    Args:\n",
    "        feature_size: the hidden feature size.\n",
    "        heads: the number of attention heads. Default is 1.\n",
    "        dropout: dropout rate. Default is 0.5.\n",
    "        num_layers: number of transformer layers. Default is 1.\n",
    "        register_hook: True to save gradients of attention layer, Default is False.\n",
    "    Examples:\n",
    "        >>> from pyhealth.models import TransformerLayer\n",
    "        >>> input = torch.randn(3, 128, 64)  # [batch size, sequence len, feature_size]\n",
    "        >>> layer = TransformerLayer(64)\n",
    "        >>> emb, cls_emb = layer(input)\n",
    "        >>> emb.shape\n",
    "        torch.Size([3, 128, 64])\n",
    "        >>> cls_emb.shape\n",
    "        torch.Size([3, 64])\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature_size, heads=1, dropout=0.5, num_layers=1):\n",
    "        super(TransformerLayer, self).__init__()\n",
    "        self.transformer = nn.ModuleList(\n",
    "            [TransformerBlock(feature_size, heads, dropout) for _ in range(num_layers)]\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, x: torch.tensor, mask: Optional[torch.tensor] = None, register_hook = False\n",
    "    ) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        \"\"\"Forward propagation.\n",
    "\n",
    "        Args:\n",
    "            x: a tensor of shape [batch size, sequence len, feature_size].\n",
    "            mask: an optional tensor of shape [batch size, sequence len], where\n",
    "                1 indicates valid and 0 indicates invalid.\n",
    "\n",
    "        Returns:\n",
    "            emb: a tensor of shape [batch size, sequence len, feature_size],\n",
    "                containing the output features for each time step.\n",
    "            cls_emb: a tensor of shape [batch size, feature_size], containing\n",
    "                the output features for the first time step.\n",
    "        \"\"\"\n",
    "        if mask is not None:\n",
    "            mask = torch.einsum(\"ab,ac->abc\", mask, mask)\n",
    "        for transformer in self.transformer:\n",
    "            x = transformer(x, mask, register_hook)\n",
    "        emb = x\n",
    "        cls_emb = x[:, 0, :]\n",
    "        return emb, cls_emb\n",
    "\n",
    "\n",
    "class Transformer(BaseModel):\n",
    "    \"\"\"Transformer model.\n",
    "\n",
    "    This model applies a separate Transformer layer for each feature, and then\n",
    "    concatenates the final hidden states of each Transformer layer. The concatenated\n",
    "    hidden states are then fed into a fully connected layer to make predictions.\n",
    "\n",
    "    Note:\n",
    "        We use separate Transformer layers for different feature_keys.\n",
    "        Currentluy, we automatically support different input formats:\n",
    "            - code based input (need to use the embedding table later)\n",
    "            - float/int based value input\n",
    "        We follow the current convention for the transformer model:\n",
    "            - case 1. [code1, code2, code3, ...]\n",
    "                - we will assume the code follows the order; our model will encode\n",
    "                each code into a vector and apply transformer on the code level\n",
    "            - case 2. [[code1, code2]] or [[code1, code2], [code3, code4, code5], ...]\n",
    "                - we will assume the inner bracket follows the order; our model first\n",
    "                use the embedding table to encode each code into a vector and then use\n",
    "                average/mean pooling to get one vector for one inner bracket; then use\n",
    "                transformer one the braket level\n",
    "            - case 3. [[1.5, 2.0, 0.0]] or [[1.5, 2.0, 0.0], [8, 1.2, 4.5], ...]\n",
    "                - this case only makes sense when each inner bracket has the same length;\n",
    "                we assume each dimension has the same meaning; we run transformer directly\n",
    "                on the inner bracket level, similar to case 1 after embedding table\n",
    "            - case 4. [[[1.5, 2.0, 0.0]]] or [[[1.5, 2.0, 0.0], [8, 1.2, 4.5]], ...]\n",
    "                - this case only makes sense when each inner bracket has the same length;\n",
    "                we assume each dimension has the same meaning; we run transformer directly\n",
    "                on the inner bracket level, similar to case 2 after embedding table\n",
    "\n",
    "        dataset: the dataset to train the model. It is used to query certain\n",
    "            information such as the set of all tokens.\n",
    "        feature_keys:  list of keys in samples to use as features,\n",
    "            e.g. [\"conditions\", \"procedures\"].\n",
    "        label_key: key in samples to use as label (e.g., \"drugs\").\n",
    "        mode: one of \"binary\", \"multiclass\", or \"multilabel\".\n",
    "        embedding_dim: the embedding dimension. Default is 128.\n",
    "        **kwargs: other parameters for the Transformer layer.\n",
    "\n",
    "    Examples:\n",
    "        >>> from pyhealth.datasets import SampleEHRDataset\n",
    "        >>> samples = [\n",
    "        ...         {\n",
    "        ...             \"patient_id\": \"patient-0\",\n",
    "        ...             \"visit_id\": \"visit-0\",\n",
    "        ...             \"list_codes\": [\"505800458\", \"50580045810\", \"50580045811\"],  # NDC\n",
    "        ...             \"list_vectors\": [[1.0, 2.55, 3.4], [4.1, 5.5, 6.0]],\n",
    "        ...             \"list_list_codes\": [[\"A05B\", \"A05C\", \"A06A\"], [\"A11D\", \"A11E\"]],  # ATC-4\n",
    "        ...             \"list_list_vectors\": [\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: SampleEHRDataset,\n",
    "        feature_keys: List[str],\n",
    "        label_key: str,\n",
    "        mode: str,\n",
    "        pretrained_emb: str = None,\n",
    "        embedding_dim: int = 128,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(Transformer, self).__init__(\n",
    "            dataset=dataset,\n",
    "            feature_keys=feature_keys,\n",
    "            label_key=label_key,\n",
    "            mode=mode,\n",
    "            pretrained_emb=pretrained_emb,\n",
    "        )\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # validate kwargs for Transformer layer\n",
    "        if \"feature_size\" in kwargs:\n",
    "            raise ValueError(\"feature_size is determined by embedding_dim\")\n",
    "\n",
    "        # the key of self.feat_tokenizers only contains the code based inputs\n",
    "        self.feat_tokenizers = {}\n",
    "        self.label_tokenizer = self.get_label_tokenizer()\n",
    "        # the key of self.embeddings only contains the code based inputs\n",
    "        self.embeddings = nn.ModuleDict()\n",
    "        # the key of self.linear_layers only contains the float/int based inputs\n",
    "        self.linear_layers = nn.ModuleDict()\n",
    "\n",
    "        # add feature transformation layers\n",
    "        for feature_key in self.feature_keys:\n",
    "            input_info = self.dataset.input_info[feature_key]\n",
    "            # sanity check\n",
    "            if input_info[\"type\"] not in [str, float, int]:\n",
    "                raise ValueError(\n",
    "                    \"Transformer only supports str code, float and int as input types\"\n",
    "                )\n",
    "            elif (input_info[\"type\"] == str) and (input_info[\"dim\"] not in [2, 3]):\n",
    "                raise ValueError(\n",
    "                    \"Transformer only supports 2-dim or 3-dim str code as input types\"\n",
    "                )\n",
    "            elif (input_info[\"type\"] in [float, int]) and (\n",
    "                input_info[\"dim\"] not in [2, 3]\n",
    "            ):\n",
    "                raise ValueError(\n",
    "                    \"Transformer only supports 2-dim or 3-dim float and int as input types\"\n",
    "                )\n",
    "            # for code based input, we need Type\n",
    "            # for float/int based input, we need Type, input_dim\n",
    "            self.add_feature_transform_layer(feature_key, input_info)\n",
    "\n",
    "        self.transformer = nn.ModuleDict()\n",
    "        for feature_key in feature_keys:\n",
    "            self.transformer[feature_key] = TransformerLayer(\n",
    "                feature_size=embedding_dim, **kwargs\n",
    "            )\n",
    "        output_size = self.get_output_size(self.label_tokenizer)\n",
    "        # transformer's output feature size is still embedding_dim\n",
    "        self.fc = nn.Linear(len(self.feature_keys) * self.embedding_dim, output_size)\n",
    "\n",
    "    def forward(self, **kwargs) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Forward propagation.\n",
    "\n",
    "        The label `kwargs[self.label_key]` is a list of labels for each patient.\n",
    "\n",
    "        Args:\n",
    "            **kwargs: keyword arguments for the model. The keys must contain\n",
    "                all the feature keys and the label key.\n",
    "\n",
    "        Returns:\n",
    "            A dictionary with the following keys:\n",
    "                loss: a scalar tensor representing the loss.\n",
    "                y_prob: a tensor representing the predicted probabilities.\n",
    "                y_true: a tensor representing the true labels.\n",
    "        \"\"\"\n",
    "        patient_emb = []\n",
    "        for feature_key in self.feature_keys:\n",
    "            input_info = self.dataset.input_info[feature_key]\n",
    "            dim_, type_ = input_info[\"dim\"], input_info[\"type\"]\n",
    "\n",
    "            # for case 1: [code1, code2, code3, ...]\n",
    "            if (dim_ == 2) and (type_ == str):\n",
    "                x = self.feat_tokenizers[feature_key].batch_encode_2d(\n",
    "                    kwargs[feature_key]\n",
    "                )\n",
    "                # (patient, event)\n",
    "                x = torch.tensor(x, dtype=torch.long, device=self.device)\n",
    "                # (patient, event, embedding_dim)\n",
    "                x = self.embeddings[feature_key](x)\n",
    "                # (patient, event)\n",
    "                mask = torch.any(x !=0, dim=2)\n",
    "\n",
    "            # for case 2: [[code1, code2], [code3, ...], ...]\n",
    "            elif (dim_ == 3) and (type_ == str):\n",
    "                x = self.feat_tokenizers[feature_key].batch_encode_3d(\n",
    "                    kwargs[feature_key]\n",
    "                )\n",
    "                # (patient, visit, event)\n",
    "                x = torch.tensor(x, dtype=torch.long, device=self.device)\n",
    "                # (patient, visit, event, embedding_dim)\n",
    "                x = self.embeddings[feature_key](x)\n",
    "                # (patient, visit, embedding_dim)\n",
    "                x = torch.sum(x, dim=2)\n",
    "                # (patient, visit)\n",
    "                mask = torch.any(x !=0, dim=2)\n",
    "\n",
    "            # for case 3: [[1.5, 2.0, 0.0], ...]\n",
    "            elif (dim_ == 2) and (type_ in [float, int]):\n",
    "                x, mask = self.padding2d(kwargs[feature_key])\n",
    "                # (patient, event, values)\n",
    "                print(len(x),x)\n",
    "                x = torch.tensor(x, dtype=torch.float, device=self.device)\n",
    "                \n",
    "                print(x.shape)\n",
    "\n",
    "                # (patient, event, embedding_dim)\n",
    "                x = self.linear_layers[feature_key](x)\n",
    "                # (patient, event)\n",
    "                mask = mask.bool().to(self.device)\n",
    "\n",
    "            # for case 4: [[[1.5, 2.0, 0.0], [1.8, 2.4, 6.0]], ...]\n",
    "            elif (dim_ == 3) and (type_ in [float, int]):\n",
    "                x, mask = self.padding3d(kwargs[feature_key])\n",
    "                # (patient, visit, event, values)\n",
    "                x = torch.tensor(x, dtype=torch.float, device=self.device)\n",
    "                # (patient, visit, embedding_dim)\n",
    "                x = torch.sum(x, dim=2)\n",
    "                x = self.linear_layers[feature_key](x)\n",
    "                mask = mask[:, :, 0]\n",
    "                mask = mask.bool().to(self.device)\n",
    "\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "            # transform x to (patient, event, embedding_dim)\n",
    "            if self.pretrained_emb != None:\n",
    "                x = self.linear_layers[feature_key](x)\n",
    "        \n",
    "            _, x = self.transformer[feature_key](x, mask, kwargs.get('register_hook'))\n",
    "            patient_emb.append(x)\n",
    "           \n",
    "\n",
    "        patient_emb = torch.cat(patient_emb, dim=1)\n",
    "\n",
    "        logits = self.fc(patient_emb)\n",
    "        return logits\n",
    "\n",
    "        \n",
    "        # obtain y_true, loss, y_prob\n",
    "        y_true = self.prepare_labels(kwargs[self.label_key], self.label_tokenizer)\n",
    "        loss = self.get_loss_function()(logits, y_true)\n",
    "        y_prob = self.prepare_y_prob(logits)\n",
    "        results = {\"loss\": loss, \"y_prob\": y_prob, \"y_true\": y_true, \"logit\": logits}\n",
    "        if kwargs.get(\"embed\", False):\n",
    "            results[\"embed\"] = patient_emb\n",
    "        \n",
    "        return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
